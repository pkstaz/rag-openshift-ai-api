import time
import asyncio
from contextlib import contextmanager
from functools import wraps
from typing import Optional, Dict, Any, Callable, List
from prometheus_client import (
    Counter, Histogram, Gauge, Info, generate_latest,
    CONTENT_TYPE_LATEST, REGISTRY, CollectorRegistry
)
from prometheus_client.exposition import start_http_server


# =============================================================================
# Metrics Registry
# =============================================================================

# Create a custom registry for the application
metrics_registry = CollectorRegistry()

# =============================================================================
# API Metrics
# =============================================================================

# Request counters
rag_api_requests_total = Counter(
    'rag_api_requests_total',
    'Total number of API requests',
    ['method', 'endpoint', 'status'],
    registry=metrics_registry
)

# Request duration histogram
rag_api_request_duration_seconds = Histogram(
    'rag_api_request_duration_seconds',
    'API request duration in seconds',
    ['method', 'endpoint'],
    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0],
    registry=metrics_registry
)

# Active requests gauge
rag_api_active_requests = Gauge(
    'rag_api_active_requests',
    'Number of active API requests',
    ['method', 'endpoint'],
    registry=metrics_registry
)

# =============================================================================
# RAG-Specific Metrics
# =============================================================================

# Query counters
rag_queries_total = Counter(
    'rag_queries_total',
    'Total number of RAG queries processed',
    ['status', 'model_used'],
    registry=metrics_registry
)

# Query processing time
rag_query_processing_time_seconds = Histogram(
    'rag_query_processing_time_seconds',
    'Total RAG query processing time in seconds',
    ['model_used'],
    buckets=[0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0],
    registry=metrics_registry
)

# Chunks retrieved distribution
rag_chunks_retrieved_total = Histogram(
    'rag_chunks_retrieved_total',
    'Distribution of chunks retrieved per query',
    ['search_type'],
    buckets=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],
    registry=metrics_registry
)

# LLM tokens generated
rag_llm_tokens_generated_total = Counter(
    'rag_llm_tokens_generated_total',
    'Total tokens generated by LLM',
    ['model_used', 'token_type'],
    registry=metrics_registry
)

# Embedding generation time
rag_embeddings_generation_time_seconds = Histogram(
    'rag_embeddings_generation_time_seconds',
    'Time spent on embedding generation in seconds',
    ['model_used'],
    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
    registry=metrics_registry
)

# =============================================================================
# Component Health Metrics
# =============================================================================

# Connection status gauges
rag_elasticsearch_connection_status = Gauge(
    'rag_elasticsearch_connection_status',
    'Elasticsearch connection status (1=up, 0=down)',
    registry=metrics_registry
)

rag_vllm_connection_status = Gauge(
    'rag_vllm_connection_status',
    'vLLM connection status (1=up, 0=down)',
    registry=metrics_registry
)

# Component performance histograms
rag_elasticsearch_search_time_seconds = Histogram(
    'rag_elasticsearch_search_time_seconds',
    'Elasticsearch search time in seconds',
    ['search_type'],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
    registry=metrics_registry
)

rag_vllm_generation_time_seconds = Histogram(
    'rag_vllm_generation_time_seconds',
    'vLLM generation time in seconds',
    ['model_used'],
    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0],
    registry=metrics_registry
)

# =============================================================================
# Error Metrics
# =============================================================================

# General error counter
rag_errors_total = Counter(
    'rag_errors_total',
    'Total number of errors',
    ['error_type', 'component'],
    registry=metrics_registry
)

# Component-specific error counters
rag_elasticsearch_errors_total = Counter(
    'rag_elasticsearch_errors_total',
    'Total number of Elasticsearch errors',
    ['error_type'],
    registry=metrics_registry
)

rag_vllm_errors_total = Counter(
    'rag_vllm_errors_total',
    'Total number of vLLM errors',
    ['error_type'],
    registry=metrics_registry
)

# =============================================================================
# Application Info
# =============================================================================

rag_app_info = Info(
    'rag_app',
    'RAG API application information',
    registry=metrics_registry
)

# =============================================================================
# Decorators for Auto-Instrumentation
# =============================================================================

def track_api_request(method: str, endpoint: str):
    """Decorator to track API requests with metrics."""
    
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            # Increment active requests
            rag_api_active_requests.labels(method=method, endpoint=endpoint).inc()
            
            start_time = time.time()
            status = "success"
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                # Increment error counter
                rag_errors_total.labels(
                    error_type=type(e).__name__,
                    component="api"
                ).inc()
                raise
            finally:
                # Record duration
                duration = time.time() - start_time
                rag_api_request_duration_seconds.labels(
                    method=method, 
                    endpoint=endpoint
                ).observe(duration)
                
                # Increment request counter
                rag_api_requests_total.labels(
                    method=method, 
                    endpoint=endpoint, 
                    status=status
                ).inc()
                
                # Decrement active requests
                rag_api_active_requests.labels(
                    method=method, 
                    endpoint=endpoint
                ).dec()
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            # Increment active requests
            rag_api_active_requests.labels(method=method, endpoint=endpoint).inc()
            
            start_time = time.time()
            status = "success"
            
            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                # Increment error counter
                rag_errors_total.labels(
                    error_type=type(e).__name__,
                    component="api"
                ).inc()
                raise
            finally:
                # Record duration
                duration = time.time() - start_time
                rag_api_request_duration_seconds.labels(
                    method=method, 
                    endpoint=endpoint
                ).observe(duration)
                
                # Increment request counter
                rag_api_requests_total.labels(
                    method=method, 
                    endpoint=endpoint, 
                    status=status
                ).inc()
                
                # Decrement active requests
                rag_api_active_requests.labels(
                    method=method, 
                    endpoint=endpoint
                ).dec()
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    
    return decorator


def track_rag_query(model_used: str = "default"):
    """Decorator to track RAG query processing."""
    
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                # Increment error counter
                rag_errors_total.labels(
                    error_type=type(e).__name__,
                    component="rag"
                ).inc()
                raise
            finally:
                # Record processing time
                duration = time.time() - start_time
                rag_query_processing_time_seconds.labels(
                    model_used=model_used
                ).observe(duration)
                
                # Increment query counter
                rag_queries_total.labels(
                    status=status,
                    model_used=model_used
                ).inc()
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"
            
            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                # Increment error counter
                rag_errors_total.labels(
                    error_type=type(e).__name__,
                    component="rag"
                ).inc()
                raise
            finally:
                # Record processing time
                duration = time.time() - start_time
                rag_query_processing_time_seconds.labels(
                    model_used=model_used
                ).observe(duration)
                
                # Increment query counter
                rag_queries_total.labels(
                    status=status,
                    model_used=model_used
                ).inc()
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    
    return decorator


# =============================================================================
# Context Managers for Timing
# =============================================================================

@contextmanager
def track_elasticsearch_search(search_type: str = "vector"):
    """Context manager to track Elasticsearch search performance."""
    
    start_time = time.time()
    try:
        yield
    except Exception as e:
        # Increment ES error counter
        rag_elasticsearch_errors_total.labels(
            error_type=type(e).__name__
        ).inc()
        raise
    finally:
        duration = time.time() - start_time
        rag_elasticsearch_search_time_seconds.labels(
            search_type=search_type
        ).observe(duration)


@contextmanager
def track_vllm_generation(model_used: str = "default"):
    """Context manager to track vLLM generation performance."""
    
    start_time = time.time()
    try:
        yield
    except Exception as e:
        # Increment vLLM error counter
        rag_vllm_errors_total.labels(
            error_type=type(e).__name__
        ).inc()
        raise
    finally:
        duration = time.time() - start_time
        rag_vllm_generation_time_seconds.labels(
            model_used=model_used
        ).observe(duration)


@contextmanager
def track_embedding_generation(model_used: str = "default"):
    """Context manager to track embedding generation performance."""
    
    start_time = time.time()
    try:
        yield
    except Exception as e:
        # Increment error counter
        rag_errors_total.labels(
            error_type=type(e).__name__,
            component="embedding"
        ).inc()
        raise
    finally:
        duration = time.time() - start_time
        rag_embeddings_generation_time_seconds.labels(
            model_used=model_used
        ).observe(duration)


# =============================================================================
# Utility Functions
# =============================================================================

def increment_llm_tokens(model_used: str, token_type: str, count: int):
    """Increment LLM tokens counter."""
    rag_llm_tokens_generated_total.labels(
        model_used=model_used,
        token_type=token_type
    ).inc(count)


def record_chunks_retrieved(search_type: str, count: int):
    """Record number of chunks retrieved."""
    rag_chunks_retrieved_total.labels(
        search_type=search_type
    ).observe(count)


def update_elasticsearch_status(is_healthy: bool):
    """Update Elasticsearch connection status."""
    status = 1 if is_healthy else 0
    rag_elasticsearch_connection_status.set(status)


def update_vllm_status(is_healthy: bool):
    """Update vLLM connection status."""
    status = 1 if is_healthy else 0
    rag_vllm_connection_status.set(status)


def record_error(error_type: str, component: str):
    """Record an error occurrence."""
    rag_errors_total.labels(
        error_type=error_type,
        component=component
    ).inc()


def record_elasticsearch_error(error_type: str):
    """Record an Elasticsearch error."""
    rag_elasticsearch_errors_total.labels(
        error_type=error_type
    ).inc()


def record_vllm_error(error_type: str):
    """Record a vLLM error."""
    rag_vllm_errors_total.labels(
        error_type=error_type
    ).inc()


# =============================================================================
# Setup and Export Functions
# =============================================================================

def setup_metrics(app_info: Optional[Dict[str, str]] = None):
    """Setup metrics with application information."""
    
    # Set application info
    if app_info:
        rag_app_info.info(app_info)
    else:
        rag_app_info.info({
            'version': '0.1.0',
            'name': 'rag-openshift-ai-api',
            'author': 'Carlos Estay'
        })


def get_metrics():
    """Get metrics in Prometheus format."""
    return generate_latest(metrics_registry)


def start_metrics_server(port: int = 8000):
    """Start metrics server on specified port."""
    start_http_server(port, registry=metrics_registry)


# =============================================================================
# Health Check Metrics
# =============================================================================

def update_component_health(component: str, is_healthy: bool):
    """Update component health status."""
    if component == "elasticsearch":
        update_elasticsearch_status(is_healthy)
    elif component == "vLLM":
        update_vllm_status(is_healthy)


def get_metrics_summary() -> Dict[str, Any]:
    """Get a summary of current metrics."""
    return {
        "total_requests": rag_api_requests_total._value.sum(),
        "active_requests": rag_api_active_requests._value.sum(),
        "total_queries": rag_queries_total._value.sum(),
        "total_errors": rag_errors_total._value.sum(),
        "elasticsearch_status": rag_elasticsearch_connection_status._value.get(),
        "vllm_status": rag_vllm_connection_status._value.get(),
    }


# =============================================================================
# API Metrics Functions
# =============================================================================

def increment_request_counter(method: str, endpoint: str, status_code: str) -> None:
    """Increment API request counter."""
    rag_api_requests_total.labels(method=method, endpoint=endpoint, status_code=status_code).inc()


def record_request_duration(method: str, endpoint: str, status_code: str, duration: float) -> None:
    """Record API request duration."""
    rag_api_request_duration.labels(method=method, endpoint=endpoint, status_code=status_code).observe(duration) 